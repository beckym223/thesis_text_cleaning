is that they had no self-awareness of their lack of predictive skills. If the CFOs
had well-calibrated forecasts the actual stock-market return would fall between
their high and low estimate 80 percent of the time. Instead, their ranges included
the actual outcome for just 36 percent of the forecasts recorded over a ten-year
period. This is quite similar to the overconfidence observed in dozens of laboratory
studies.
Overconfidence and excessive extrapolation are just two examples of biased
beliefs that have been documented by psychologists studying human judgment.
This literature began with the original three heuristics studied by Kahneman and
Tversky - availability, representativeness, and anchoring and adjustment - but
many others have been investigated and documented since then: hindsight bias,
projection bias, excessive attention to whatever feature of the environment is most
salient, etc. For each of these biases and many more, economists have created
descriptive models to try to make the implications of the biases more specific and
rigorous.
The fact that there is a long list of biases is both a blessing and a curse. The
blessing is that there are a multitude of interesting ways in which human judgment
diverges from rational expectations, each of which offers the possibility of providing
useful insights into economic behavior. The curse is that the length of the list seems
to offer theorists a dangerously large number of degrees of freedom. Although I do
not dismiss this latter risk out of hand, I think good scientific practices can mitigate
this degrees-of-freedom risk.
The most important thing to remember is that all these biases have empirical sup-
port, and many of the laboratory findings have subsequently been replicated in the
field. Thus some discipline has already been imposed: behavioral economists can
draw on a long list of potential explanatory factors, but for each there is at least some
evidence that the factor is real. Compare this with the degrees of freedom available
in traditional rationality-based models. For example, consider the all-purpose fudge
factor: transaction costs. In the abstract such costs can explain many anomalies,
but unless those costs can be measured the use of the concept is undisciplined. If
we limit ourselves to variables that have an empirical basis, all of economics will
become more disciplined.
Of course I do not mean to suggest that behavioral economic theory is a finished
product. The field is new and growing rapidly. One goal should be to devise theories
that are not just portable extensions of existing models but also testable extensions.
I will leave it to Rabin to decide where to insert the letter T into his PEEM acronym.
V. Supposedly Irrelevant Factors
It is rare that economic theory makes predictions about magnitudes. Mostly theo-
ries make predictions about the sign of an effect. Demand curves slope down; supply
curves slope up. When a clever theorist is able to extract a more precise prediction
from the theory, things can get interesting. The equity premium puzzle is a case in
point. The first-order prediction that stocks are riskier than bonds and so should
earn a higher rate of return is resoundingly supported by the historical data. But
Mehra and Prescott (1985) showed that the standard model cannot simultaneously
explain the low historical risk-free rate and an equity premium in the neighbor